{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "641022a7-5f7e-4033-b4c9-0768789a562c",
   "metadata": {},
   "source": [
    "## Set up dependencies, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15bfb8-cd93-4d56-b026-d6dee26f001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install d2l==1.0.3\n",
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d9d15f-6327-4d79-bf2d-5478bbf12fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c231497-c07e-46fb-9bd4-5b8476819e9f",
   "metadata": {},
   "source": [
    "## Set random seed to ensure reproducibility\n",
    "\n",
    "**TODO**: This doesn't seem to be working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8782d4c-ec2e-4a44-b177-2fae12caa170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"Ensures reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a5448c-f50c-4cfa-a026-abe19a8436c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 765 # ナムコプロ最強"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1cc3e8-9200-4bf5-90fb-6e453644178f",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We use the following CNN architecture structured similarly to architectures such as VGG (albeit much smaller, of course):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8075df84-ff95-4737-86cb-b28d49b7f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_FashionMNIST(d2l.Classifier):\n",
    "    def __init__(self, lr=1e-4, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.LazyConv2d(96, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.LazyConv2d(128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.LazyLinear(110),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.LazyLinear(10)\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c377ff4b-64d2-494e-865e-2760d5a624cf",
   "metadata": {},
   "source": [
    "Note that we use Kaiming initialization over Xavier (Glorot) as this works better with ReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d04df0-098c-4c5f-9986-316877a51a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(module):\n",
    "    if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "        nn.init.kaiming_normal_(module.weight, nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f5016d-674f-4f3b-b7a5-b0a7c792fc25",
   "metadata": {},
   "source": [
    "We instantiate the model and inspect its properties, e.g. parameter count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f45ed65-fd98-494b-936a-cab389236f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(SEED) # Set for reproducibility\n",
    "\n",
    "X = torch.randn(1, 1, 28, 28)\n",
    "model = CNN_FashionMNIST(lr=5e-4)\n",
    "model(X)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32215a91-8fcf-441d-b7ba-af833965693a",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "To allow the model to generalize better, we augment the data by applying affine transformations such as a horizontal flip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5971225-5d35-45f6-96f0-36622e56581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(SEED) # Set for reproducibility\n",
    "\n",
    "data = d2l.FashionMNIST(batch_size=128, resize=(28, 28))\n",
    "trainer = d2l.Trainer(max_epochs=20, num_gpus=1)\n",
    "\n",
    "def augment_transform(train):\n",
    "    t = [transforms.Resize((28, 28)), transforms.ToTensor()]\n",
    "\n",
    "    # Only do this during training, not testing\n",
    "    if train:\n",
    "        t.insert(1, transforms.RandomHorizontalFlip(p=0.5))\n",
    "        \n",
    "    return transforms.Compose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4e3e9-e7a9-4a26-9e4b-4a6b07a2ea36",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c51683-7204-4990-bbf3-ba1428221017",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(SEED) # Set for reproducibility\n",
    "\n",
    "data.get_transform = augment_transform\n",
    "model.apply_init([next(iter(data.get_dataloader(True)))[0]], init_cnn)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f094227a-5432-443b-a334-b50682d631ee",
   "metadata": {},
   "source": [
    "## Measure accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3686d3-f2eb-4834-a8ef-a7e15122a858",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(SEED) # Set for reproducibility\n",
    "\n",
    "test_iter = data.get_dataloader(train=False)\n",
    "model.eval()\n",
    "\n",
    "metric = d2l.Accumulator(2) \n",
    "\n",
    "# Test on all batches (TODO: Ask Ms. if there's specific code we need to execute\n",
    "# to measure accuracy consistently for all groups in our class)\n",
    "for X, y in test_iter:\n",
    "    X, y = X.to(d2l.try_gpu()), y.to(d2l.try_gpu())\n",
    "    metric.add(d2l.accuracy(model(X), y), y.numel())\n",
    "\n",
    "final_test_acc = metric[0] / metric[1]\n",
    "print(f'Final Test Accuracy: {final_test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a51cf9-0eec-48d1-bebf-b6844ecafec5",
   "metadata": {},
   "source": [
    "Expected accuracy: 92.42%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
